{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83832900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#expand cell width to 100%\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "276ccc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas \n",
    "import pandas as pd\n",
    "#import numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3400b51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the address of the dataframe containing the pre-processed dataset\n",
    "#dataFramePickleAddress=\"C:/ML4Sci/Ml4Sci_GRS_abundance_estimation/Dataset/GRSFiveDegreeSectionPreProcessedDataset.pkl\"\n",
    "dataFramePickleAddress=\"D:/Non-academic/GSOC23/Ml4Sci_GRS_abundance_estimation/Dataset/GRSFiveDegreeSectionPreProcessedDataset.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b151d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the dataframe\n",
    "dataframe=pd.read_pickle(dataFramePickleAddress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ac4239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the dataframe\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79629eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a variable epsilon, which contains a very small value that is added to all inputs and outputs to make sure no values are 0\n",
    "epsilon=1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00ab13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the abundance values for the seven elements for which the model is to be trained\n",
    "#aluminium\n",
    "aluminiumAbundances=dataframe['Aluminum'].to_numpy()+epsilon\n",
    "#calcium\n",
    "calciumAbundances=dataframe['Calcium'].to_numpy()+epsilon\n",
    "#iron\n",
    "ironAbundances=dataframe['Iron'].to_numpy()+epsilon\n",
    "#magnesium\n",
    "magnesiumAbundances=dataframe['Magnesium'].to_numpy()+epsilon\n",
    "#oxygen\n",
    "oxygenAbundances=dataframe['Oxygen'].to_numpy()+epsilon\n",
    "#silicon\n",
    "siliconAbundances=dataframe['Silicon'].to_numpy()+epsilon\n",
    "#titanium\n",
    "titaniumAbundances=dataframe['Titanium'].to_numpy()+epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3460a907",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get abundance values for the three nuclear elements\n",
    "potassiumAbundances=dataframe['Potassium'].to_numpy()+epsilon\n",
    "thoriumAbundances=dataframe['Thorium'].to_numpy()+epsilon\n",
    "uraniumAbundances=dataframe['Uranium'].to_numpy()+epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8638aab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale nuclear abundance values between 0 and 1\n",
    "potassiumAbundances=(potassiumAbundances-np.amin(potassiumAbundances))/np.ptp(potassiumAbundances)\n",
    "thoriumAbundances=(thoriumAbundances-np.amin(thoriumAbundances))/np.ptp(thoriumAbundances)\n",
    "uraniumAbundances=(uraniumAbundances-np.amin(uraniumAbundances))/np.ptp(uraniumAbundances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78ae584",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an list which contains the element names to be estimated\n",
    "regularElementNames=['Aluminum',\n",
    "                     'Calcium',\n",
    "                     'Iron',\n",
    "                     'Magnesium',\n",
    "                     'Oxygen',\n",
    "                     'Silicon',\n",
    "                     'Titanium']\n",
    "#conver the list to a numpy array\n",
    "regularElementNames=np.array(regularElementNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f5325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the elemental abundances into a single matrix\n",
    "regularElementalAbundances=np.dstack([aluminiumAbundances,\n",
    "                                      calciumAbundances,\n",
    "                                      ironAbundances,\n",
    "                                      magnesiumAbundances,\n",
    "                                      oxygenAbundances,\n",
    "                                      siliconAbundances,\n",
    "                                      titaniumAbundances])\n",
    "#reshape the abundance matrix\n",
    "regularElementalAbundances=regularElementalAbundances[0,:,:]\n",
    "#rescale weigth percent values from % (0-100) to franctions (0-1)\n",
    "regularElementalAbundances=regularElementalAbundances/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7dd49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an list which contains the element names to be estimated\n",
    "nuclearElementNames=['Potassium',\n",
    "                     'Thorium',\n",
    "                     'Uranium']\n",
    "#conver the list to a numpy array\n",
    "nuclearElementNames=np.array(nuclearElementNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33eee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an array containing the names of all elements\n",
    "allElementNames=np.hstack([regularElementNames,nuclearElementNames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca4b854",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the elemental abundances into a single matrix\n",
    "nuclearElementalAbundances=np.dstack([potassiumAbundances,\n",
    "                                      thoriumAbundances,\n",
    "                                      uraniumAbundances])\n",
    "#reshape the abundance matrix\n",
    "nuclearElementalAbundances=nuclearElementalAbundances[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e32348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the pre-processed spectra as a numpy array\n",
    "preprocessedSpectra=dataframe['Normalized Continuum Removed Denoised Log Scaled Spectra'].to_numpy()\n",
    "#reshape the numpy array\n",
    "preprocessedSpectra=np.vstack(preprocessedSpectra)+epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6d40e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the eneergy values for each band\n",
    "gain=17.8 #keV/channel\n",
    "energyBands=np.arange(0,512,1)*gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa371af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the index of the last relavent band\n",
    "finalRelaventBandIndex=np.argmin(np.abs(energyBands-8000))\n",
    "#compute the index of the first relavent band\n",
    "firstRelaventBandIndex=finalRelaventBandIndex-preprocessedSpectra.shape[1]+1\n",
    "#get the energies of the relavent bands\n",
    "relaventEnergyBands=energyBands[firstRelaventBandIndex:finalRelaventBandIndex+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5cf87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the variables no longer needed from memory\n",
    "del firstRelaventBandIndex\n",
    "del finalRelaventBandIndex\n",
    "del energyBands\n",
    "del gain\n",
    "del dataframe\n",
    "del dataFramePickleAddress\n",
    "del aluminiumAbundances\n",
    "del calciumAbundances\n",
    "del ironAbundances\n",
    "del magnesiumAbundances\n",
    "del oxygenAbundances\n",
    "del siliconAbundances\n",
    "del titaniumAbundances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aabc366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pyplot from matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0badb81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set plot parameters\n",
    "baseFontSize=18\n",
    "noOfBinsForHistogram=100\n",
    "noOfXticks=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31fb567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a figure \n",
    "figure,axes=plt.subplots(nrows=1,\n",
    "                         ncols=7,\n",
    "                         figsize=(35,5),\n",
    "                         dpi=200)\n",
    "#iterate over all elements\n",
    "for i in range(regularElementNames.shape[0]):\n",
    "    #plot the histogram\n",
    "    temp=axes[i].hist(regularElementalAbundances[:,i],\n",
    "                      bins=noOfBinsForHistogram)\n",
    "    #set the title of the figure\n",
    "    axes[i].set_title(regularElementNames[i],fontsize=baseFontSize*1.2)\n",
    "    #set the axis labels\n",
    "    axes[i].set_xlabel(\"Wt frac.\",fontsize=baseFontSize*1.2)\n",
    "    axes[i].set_ylabel(\"Freq\",fontsize=baseFontSize*1.2)\n",
    "    #set the ticks and their label sizes\n",
    "    axes[i].set_xticks(np.arange(np.amin(regularElementalAbundances[:,i]),\n",
    "                                 np.amax(regularElementalAbundances[:,i])+np.ptp(regularElementalAbundances[:,i])/noOfXticks,\n",
    "                                 np.ptp(regularElementalAbundances[:,i])/noOfXticks),\n",
    "                       labels=np.round(np.arange(np.amin(regularElementalAbundances[:,i]),\n",
    "                                                 np.amax(regularElementalAbundances[:,i])+np.ptp(regularElementalAbundances[:,i])/noOfXticks,\n",
    "                                                 np.ptp(regularElementalAbundances[:,i])/noOfXticks),\n",
    "                                       2),\n",
    "                       fontsize=baseFontSize)\n",
    "    #set the margins\n",
    "    axes[i].margins(0.01)\n",
    "    \n",
    "#add a title\n",
    "figure.suptitle(\"Distribution of abundance values\",\n",
    "                fontsize=baseFontSize*1.5)\n",
    "#adjust the layout\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c10303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a figure \n",
    "figure,axes=plt.subplots(nrows=1,\n",
    "                         ncols=3,\n",
    "                         figsize=(15,5),\n",
    "                         dpi=200)\n",
    "#iterate over all elements\n",
    "for i in range(nuclearElementNames.shape[0]):\n",
    "    #plot the histogram\n",
    "    temp=axes[i].hist(nuclearElementalAbundances[:,i],\n",
    "                      bins=noOfBinsForHistogram)\n",
    "    #set the title of the figure\n",
    "    axes[i].set_title(nuclearElementNames[i],fontsize=baseFontSize*1.2)\n",
    "    #set the axis labels\n",
    "    axes[i].set_xlabel(\"PPM\",fontsize=baseFontSize*1.2)\n",
    "    axes[i].set_ylabel(\"Freq\",fontsize=baseFontSize*1.2)\n",
    "    #set the ticks and their label sizes\n",
    "    axes[i].set_xticks(np.arange(np.amin(nuclearElementalAbundances[:,i]),\n",
    "                                 np.amax(nuclearElementalAbundances[:,i])+np.ptp(nuclearElementalAbundances[:,i])/noOfXticks,\n",
    "                                 np.ptp(nuclearElementalAbundances[:,i])/noOfXticks),\n",
    "                       labels=np.round(np.arange(np.amin(nuclearElementalAbundances[:,i]),\n",
    "                                                 np.amax(nuclearElementalAbundances[:,i])+np.ptp(nuclearElementalAbundances[:,i])/noOfXticks,\n",
    "                                                 np.ptp(nuclearElementalAbundances[:,i])/noOfXticks),\n",
    "                                       2),\n",
    "                       fontsize=baseFontSize)\n",
    "    #set the margins\n",
    "    axes[i].margins(0.01)\n",
    "    \n",
    "#add a title\n",
    "figure.suptitle(\"Distribution of abundance values\",\n",
    "                fontsize=baseFontSize*1.5)\n",
    "#adjust the layout\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f21cd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a figure\n",
    "plt.figure(figsize=(30,15),\n",
    "           dpi=100)\n",
    "#and plot all the spectra\n",
    "for i in range(preprocessedSpectra.shape[0]):\n",
    "    plt.plot(relaventEnergyBands,\n",
    "             preprocessedSpectra[i,:],\n",
    "             lw=5)\n",
    "#annotate the figure\n",
    "plt.title(\"Preprocessed GRS Spectra\",\n",
    "          fontsize=baseFontSize*1.8)\n",
    "plt.xticks(np.arange(np.amin(relaventEnergyBands),\n",
    "                     np.amax(relaventEnergyBands)+np.ptp(relaventEnergyBands)/noOfXticks,\n",
    "                     np.ptp(relaventEnergyBands)/noOfXticks),\n",
    "           fontsize=baseFontSize*1.2)\n",
    "plt.yticks(np.arange(np.amin(preprocessedSpectra),\n",
    "                     np.amax(preprocessedSpectra)+np.ptp(preprocessedSpectra)/noOfXticks,\n",
    "                     np.ptp(preprocessedSpectra)/noOfXticks),\n",
    "           labels=np.round(np.arange(np.amin(preprocessedSpectra),\n",
    "                                     np.amax(preprocessedSpectra)+np.ptp(preprocessedSpectra)/noOfXticks,\n",
    "                                     np.ptp(preprocessedSpectra)/noOfXticks),\n",
    "                           2),\n",
    "           fontsize=baseFontSize*1.2)\n",
    "plt.xlabel(\"KeV\",\n",
    "           fontsize=baseFontSize*1.5)\n",
    "plt.ylabel(\"log(Counts/min) ratioed\",\n",
    "           fontsize=baseFontSize*1.5)\n",
    "plt.margins(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f788bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import PCA from sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "#import cosine distance from scipy\n",
    "from scipy.spatial.distance import cosine as cosineDistance\n",
    "\n",
    "#define a function which given an array of spectra, explained-variance ratio, and no of spectra to be selected\n",
    "#returns the indices of most interesting (most unlike the others) spectra\n",
    "def extractMostExtremeSpectraWithDEMUD(spectra,varianceToExplain,noOfSpectraToRetrive):\n",
    "    #create an array to hold the indices of the selected (interesting) super-pixels\n",
    "    selectedSpectraIndices=[]\n",
    "    #create a PCA object which explains over 95% of the variance in the data\n",
    "    pcaObject=PCA(n_components=varianceToExplain,\n",
    "                  svd_solver='auto')\n",
    "    #compute the PCA model for the spectra and use it to reconstruct the orginal spectra\n",
    "    reconstructedSpectra=pcaObject.inverse_transform(pcaObject.fit_transform(spectra))\n",
    "    #create an array to save the reconstruction error (cosine distance)\n",
    "    reconstructionErrors=np.full(spectra.shape[0],\n",
    "                                 np.nan)\n",
    "    #compute the cosine distance between the orginal and reconstructed spectra\n",
    "    for i in range(spectra.shape[0]):\n",
    "        reconstructionErrors[i]=cosineDistance(spectra[i,:],\n",
    "                                               reconstructedSpectra[i,:])\n",
    "    #save the index of the spectra with the greatest error\n",
    "    selectedSpectraIndices.append(np.argmax(reconstructionErrors))\n",
    "\n",
    "    #iteratively extract the most dissimar spectra\n",
    "    for i in range(noOfSpectraToRetrive-1):\n",
    "        #fit PCA to the selected spectra\n",
    "        pcaObject.fit(spectra[selectedSpectraIndices,:])\n",
    "        #apply PCA and then reconstruct the spectra\n",
    "        reconstructedSpectra=pcaObject.inverse_transform(pcaObject.transform(spectra))\n",
    "        #create an array to save the reconstruction error (cosine distance)\n",
    "        reconstructionErrors=np.full(spectra.shape[0],np.nan)\n",
    "        #compute the cosine distance between the orginal and reconstructed spectra\n",
    "        for i in range(spectra.shape[0]):\n",
    "            reconstructionErrors[i]=cosineDistance(spectra[i,:],\n",
    "                                                   reconstructedSpectra[i,:])\n",
    "        #remove the error of the selected pixels\n",
    "        reconstructionErrors=np.delete(reconstructionErrors,\n",
    "                                       selectedSpectraIndices)\n",
    "        #get the index of the spectra with the greatest error\n",
    "        selectedSpectraIndices.append(np.delete(np.arange(0,spectra.shape[0],1),\n",
    "                                                selectedSpectraIndices,axis=0)[np.argmax(reconstructionErrors)])\n",
    "        \n",
    "    return selectedSpectraIndices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61792c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters for extracting differing spectra\n",
    "varianceToBeExplainedDuringDEMUD=0.98\n",
    "noOfExtremeSpectraToBeRetrieved=179\n",
    "#get indices of the most extreme spectra\n",
    "extremeIndices=extractMostExtremeSpectraWithDEMUD(preprocessedSpectra,\n",
    "                                                  varianceToExplain=varianceToBeExplainedDuringDEMUD,\n",
    "                                                  noOfSpectraToRetrive=noOfExtremeSpectraToBeRetrieved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50b6ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the subset data\n",
    "#spectra\n",
    "preprocessedSpectra=preprocessedSpectra[extremeIndices,:]\n",
    "#regular abundances\n",
    "regularElementalAbundances=regularElementalAbundances[extremeIndices,:]\n",
    "#nuclear abundances\n",
    "nuclearElementalAbundances=nuclearElementalAbundances[extremeIndices,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ce3ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a figure \n",
    "figure,axes=plt.subplots(nrows=1,\n",
    "                         ncols=7,\n",
    "                         figsize=(35,5),\n",
    "                         dpi=200)\n",
    "#iterate over all elements\n",
    "for i in range(regularElementNames.shape[0]):\n",
    "    #plot the histogram\n",
    "    temp=axes[i].hist(regularElementalAbundances[:,i],\n",
    "                      bins=noOfBinsForHistogram)\n",
    "    #set the title of the figure\n",
    "    axes[i].set_title(regularElementNames[i],fontsize=baseFontSize*1.2)\n",
    "    #set the axis labels\n",
    "    axes[i].set_xlabel(\"Wt frac.\",fontsize=baseFontSize*1.2)\n",
    "    axes[i].set_ylabel(\"Freq\",fontsize=baseFontSize*1.2)\n",
    "    #set the ticks and their label sizes\n",
    "    axes[i].set_xticks(np.arange(np.amin(regularElementalAbundances[:,i]),\n",
    "                                 np.amax(regularElementalAbundances[:,i])+np.ptp(regularElementalAbundances[:,i])/noOfXticks,\n",
    "                                 np.ptp(regularElementalAbundances[:,i])/noOfXticks),\n",
    "                       labels=np.round(np.arange(np.amin(regularElementalAbundances[:,i]),\n",
    "                                                 np.amax(regularElementalAbundances[:,i])+np.ptp(regularElementalAbundances[:,i])/noOfXticks,\n",
    "                                                 np.ptp(regularElementalAbundances[:,i])/noOfXticks),\n",
    "                                       2),\n",
    "                       fontsize=baseFontSize)\n",
    "    #set the margins\n",
    "    axes[i].margins(0.01)\n",
    "    \n",
    "#add a title\n",
    "figure.suptitle(\"Distribution of abundance values\",\n",
    "                fontsize=baseFontSize*1.5)\n",
    "#adjust the layout\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f49b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a figure \n",
    "figure,axes=plt.subplots(nrows=1,\n",
    "                         ncols=3,\n",
    "                         figsize=(15,5),\n",
    "                         dpi=200)\n",
    "#iterate over all elements\n",
    "for i in range(nuclearElementNames.shape[0]):\n",
    "    #plot the histogram\n",
    "    temp=axes[i].hist(nuclearElementalAbundances[:,i],\n",
    "                      bins=noOfBinsForHistogram)\n",
    "    #set the title of the figure\n",
    "    axes[i].set_title(nuclearElementNames[i],fontsize=baseFontSize*1.2)\n",
    "    #set the axis labels\n",
    "    axes[i].set_xlabel(\"PPM\",fontsize=baseFontSize*1.2)\n",
    "    axes[i].set_ylabel(\"Freq\",fontsize=baseFontSize*1.2)\n",
    "    #set the ticks and their label sizes\n",
    "    axes[i].set_xticks(np.arange(np.amin(nuclearElementalAbundances[:,i]),\n",
    "                                 np.amax(nuclearElementalAbundances[:,i])+np.ptp(nuclearElementalAbundances[:,i])/noOfXticks,\n",
    "                                 np.ptp(nuclearElementalAbundances[:,i])/noOfXticks),\n",
    "                       labels=np.round(np.arange(np.amin(nuclearElementalAbundances[:,i]),\n",
    "                                                 np.amax(nuclearElementalAbundances[:,i])+np.ptp(nuclearElementalAbundances[:,i])/noOfXticks,\n",
    "                                                 np.ptp(nuclearElementalAbundances[:,i])/noOfXticks),\n",
    "                                       2),\n",
    "                       fontsize=baseFontSize)\n",
    "    #set the margins\n",
    "    axes[i].margins(0.01)\n",
    "    \n",
    "#add a title\n",
    "figure.suptitle(\"Distribution of abundance values\",\n",
    "                fontsize=baseFontSize*1.5)\n",
    "#adjust the layout\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8937b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a figure\n",
    "plt.figure(figsize=(30,15),\n",
    "           dpi=100)\n",
    "#and plot all the spectra\n",
    "for i in range(preprocessedSpectra.shape[0]):\n",
    "    plt.plot(relaventEnergyBands,\n",
    "             preprocessedSpectra[i,:],\n",
    "             lw=5)\n",
    "#annotate the figure\n",
    "plt.title(\"Preprocessed GRS Spectra\",\n",
    "          fontsize=baseFontSize*1.8)\n",
    "plt.xticks(np.arange(np.amin(relaventEnergyBands),\n",
    "                     np.amax(relaventEnergyBands)+np.ptp(relaventEnergyBands)/noOfXticks,\n",
    "                     np.ptp(relaventEnergyBands)/noOfXticks),\n",
    "           fontsize=baseFontSize*1.2)\n",
    "plt.yticks(np.arange(np.amin(preprocessedSpectra),\n",
    "                     np.amax(preprocessedSpectra)+np.ptp(preprocessedSpectra)/noOfXticks,\n",
    "                     np.ptp(preprocessedSpectra)/noOfXticks),\n",
    "           labels=np.round(np.arange(np.amin(preprocessedSpectra),\n",
    "                                     np.amax(preprocessedSpectra)+np.ptp(preprocessedSpectra)/noOfXticks,\n",
    "                                     np.ptp(preprocessedSpectra)/noOfXticks),\n",
    "                           2),\n",
    "           fontsize=baseFontSize*1.2)\n",
    "plt.xlabel(\"KeV\",\n",
    "           fontsize=baseFontSize*1.5)\n",
    "plt.ylabel(\"log(Counts/min) ratioed\",\n",
    "           fontsize=baseFontSize*1.5)\n",
    "plt.margins(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e062271",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954ab6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set a global seed value\n",
    "globalSeed=23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f64f50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the number of channels in the pre-processed spectra\n",
    "noOfChannels=preprocessedSpectra.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f51bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an input layer\n",
    "inputLayer=tf.keras.Input(shape=(noOfChannels,\n",
    "                                 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72e76d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function which given a feature volume, applies a single convolutional block to it\n",
    "#the convolution block consists of\n",
    "#Convolutional layer; Activation; Batch Normalization; Dropout\n",
    "#the number of filters, their sizes, strideactivation function, and dropout rate are specified\n",
    "def createConvolutionalBlock(inputVolume,noOfFilters,kernelSize,strideSize,dropoutRate):\n",
    "    #create a convolutional block\n",
    "    convolutionalLayer=tf.keras.layers.Conv1D(filters=noOfFilters,\n",
    "                                                   kernel_size=kernelSize,\n",
    "                                                   strides=strideSize,\n",
    "                                                   padding='valid')\n",
    "    #add the 1st Conv layer to the graph\n",
    "    volume=convolutionalLayer(inputVolume)\n",
    "\n",
    "    #apply Relu activation\n",
    "    preluActivation=tf.keras.layers.PReLU()\n",
    "    #add the 1st activation layer to the graph\n",
    "    volume=preluActivation(volume)\n",
    "\n",
    "    #apply batch normalization\n",
    "    batchNormalization=tf.keras.layers.BatchNormalization()\n",
    "    #add the 1st batch-norm layer to the graph\n",
    "    volume=batchNormalization(volume)\n",
    "\n",
    "    #apply dropout\n",
    "    dropoutLayer=tf.keras.layers.Dropout(dropoutRate,\n",
    "                                         noise_shape=None,\n",
    "                                         seed=globalSeed)\n",
    "    #add the 1st dropout layer to the graph\n",
    "    volume=dropoutLayer(volume)\n",
    "    \n",
    "    return volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc55cdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list containing the number of features to be outputted by each Conv block\n",
    "noOfChannelsInEachConvBlock=[128,256,512,1024]\n",
    "#create a list containing the sizes filter for each Conv block\n",
    "filterSizesForEachConvBlock=[7,5,3,3]\n",
    "#create a list containing the strides for each Conv block\n",
    "strideSizesForEachConvBlock=[3,3,2,2]\n",
    "#create a list containing the dropout rate for each Conv block\n",
    "dropoutForEachConvBlock=[0.5,0.5,0.5,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48300856",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a NN (Neural Network) graph containing just the input layer\n",
    "regularElementFeatures=inputLayer\n",
    "nuclearElementFeatures=inputLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae79429",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add Convolutional blocks to create the feature extractor for regular elements\n",
    "\n",
    "for i in range(len(noOfChannelsInEachConvBlock)):\n",
    "    #create a convolutional block\n",
    "    regularElementFeatures=createConvolutionalBlock(regularElementFeatures,\n",
    "                                                    noOfChannelsInEachConvBlock[i],\n",
    "                                                    filterSizesForEachConvBlock[i],\n",
    "                                                    strideSizesForEachConvBlock[i],\n",
    "                                                    dropoutForEachConvBlock[i])\n",
    "    \n",
    "    print(f\"Shape of the tensor outputted by the 0th Conv. Block {regularElementFeatures.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b06171c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten the features for the regular elemnents\n",
    "regularElementFeatures=tf.keras.layers.Flatten()(regularElementFeatures)\n",
    "print(f\"Shape of flattened features {regularElementFeatures.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf602adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list containing the number of features to be outputted by each Conv block\n",
    "noOfChannelsInEachConvBlock=[128,256,512]\n",
    "#create a list containing the sizes filter for each Conv block\n",
    "filterSizesForEachConvBlock=[7,5,3]\n",
    "#create a list containing the strides for each Conv block\n",
    "strideSizesForEachConvBlock=[3,3,2]\n",
    "#create a list containing the dropout rate for each Conv block\n",
    "dropoutForEachConvBlock=[0.5,0.5,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbc5f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add Convolutional blocks to create the feature extractor for regular elements\n",
    "\n",
    "for i in range(len(noOfChannelsInEachConvBlock)):\n",
    "    #create a convolutional block\n",
    "    nuclearElementFeatures=createConvolutionalBlock(nuclearElementFeatures,\n",
    "                                                    noOfChannelsInEachConvBlock[i],\n",
    "                                                    filterSizesForEachConvBlock[i],\n",
    "                                                    strideSizesForEachConvBlock[i],\n",
    "                                                    dropoutForEachConvBlock[i])\n",
    "    \n",
    "    print(f\"Shape of the tensor outputted by the 0th Conv. Block {nuclearElementFeatures.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfeec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten the features for the nuclear elements\n",
    "nuclearElementFeatures=tf.keras.layers.Flatten()(nuclearElementFeatures)\n",
    "print(f\"Shape of flattened features {nuclearElementFeatures.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7a3707",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the regular elements' abundances from the generated features\n",
    "#it consists of three steps\n",
    "#1. Apply a dense layer with 7 nodes without any activation\n",
    "#2. Compute the absolute value of the values computed by dense layer\n",
    "#3. Compute the l1-norm of the 7 regular elements and and divide them by it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d260a839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function which given the output of a layer, ensures the sum of the values is one\n",
    "#it does this by computing the sum of the nodes and dividing each note by it\n",
    "def estimateAbundances(inputNodes,name):\n",
    "    sampleWiseSums=tf.keras.backend.sum(inputNodes,\n",
    "                                        axis=-1,\n",
    "                                        keepdims=True)\n",
    "    sampleWiseSums=tf.repeat(sampleWiseSums,\n",
    "                             sampleWiseSums.shape[-1],\n",
    "                             axis=-1)\n",
    "    return tf.math.divide(inputNodes,\n",
    "                          sampleWiseSums+1e-10,\n",
    "                          name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdef58f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a fully connected layer to the network (output layer)\n",
    "regularElementStage1=tf.keras.layers.Dense(7,activation='relu')(regularElementFeatures)\n",
    "\n",
    "#add a normalization layer to the network\n",
    "regularAbundanceEmbedding=tf.nn.softmax(regularElementStage1,\n",
    "                                        name=\"Regular_Abundances\")\n",
    "\n",
    "\n",
    "#print shape of abundances\n",
    "print(f\"Unscaled regular element shape {regularAbundanceEmbedding.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f954c684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the abundances for the nuclear elements from their features\n",
    "nuclearAbundanceEmbedding=tf.keras.layers.Dense(3,activation='relu',name=\"Nuclear_Abundances\")(nuclearElementFeatures)\n",
    "#print shape of abundances\n",
    "print(f\"Unscaled regular element shape {nuclearAbundanceEmbedding.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3191ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concattenate the two abundances\n",
    "fullAbundanceEmbedding=tf.concat([regularAbundanceEmbedding,nuclearAbundanceEmbedding],\n",
    "                                 axis=-1)\n",
    "\n",
    "print(f\"All element shape {fullAbundanceEmbedding.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e49bcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define regularization for the element-wise spectra\n",
    "#the regularizer encourages the elemental spectra to be different\n",
    "#this is done by computing the pairwise cosine distances, summing them up and maximizing this sum\n",
    "\n",
    "#as these weights are from seperate (parallel)layers this regularization could not be implemented as inheriting the kernel regularization class\n",
    "#therefore it is implemented as a loss. As such it recieves the true and predicted values but ignores them\n",
    "class spectralDisimilarityRegularization(tf.keras.losses.Loss):\n",
    "    def call(self,linearLayerWeights,_):\n",
    "        #normalize the weights\n",
    "        linearLayerWeights=tf.math.l2_normalize(linearLayerWeights,\n",
    "                                                axis=-2,\n",
    "                                                epsilon=1e-1)\n",
    "\n",
    "        #multiply the weights by their transpose to get the dot products (provided the weight vectors have an l2-norm of 1)\n",
    "        #sum the dot products up to get a value proportional to the sum of pairwise dot products\n",
    "        unmixingSpectralSimilarity=tf.math.reduce_sum(tf.linalg.matmul(linearLayerWeights,\n",
    "                                                                       linearLayerWeights,\n",
    "                                                                       transpose_b=True),\n",
    "                                                      name=\"Spectral_Disiimilarity_Regularization\")\n",
    "\n",
    "        #return the similarity estimate which is the regularization value\n",
    "        return unmixingSpectralSimilarity\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ae2cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a composite constraint to be applied to the weights of the hidden layers which are the weights\n",
    "class UnitNormNonNegetivityConstraint(tf.keras.constraints.Constraint):\n",
    "    def __init__(self,axis=0):\n",
    "        self.axis=axis\n",
    "    def __call__(self, w):\n",
    "        #apply positivity constraint\n",
    "        w=w*tf.cast(tf.greater_equal(w,0.0),\n",
    "                    tf.keras.backend.floatx())\n",
    "        \n",
    "        return w\n",
    "\n",
    "\n",
    "\n",
    "#create the composite constraint by combining the two constraints\n",
    "unitNormNonNegetivityConstraint=UnitNormNonNegetivityConstraint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba91f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the linear hidden layer as a combination of ten hidden layers each connected to a single abundance value\n",
    "elementWiseHiddenLayers=[]\n",
    "abundanceScaledElementalSpectra=[]\n",
    "for i in range(fullAbundanceEmbedding.shape[-1]):\n",
    "    temp=tf.keras.layers.Dense(noOfChannels,activation=None,use_bias=False,kernel_constraint=unitNormNonNegetivityConstraint,name=allElementNames[i]+\"_Spectra\")\n",
    "    elementWiseHiddenLayers.append(temp)\n",
    "    temp=temp(tf.expand_dims(fullAbundanceEmbedding[:,i],-1))\n",
    "    abundanceScaledElementalSpectra.append(temp)\n",
    "    del temp\n",
    "    print(f\"Shape of the spectra outputed by {allElementNames[i]} {abundanceScaledElementalSpectra[-1].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9ca2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stack the abundance scaled elemental spectra together\n",
    "abundanceScaledElementalSpectra=tf.stack(abundanceScaledElementalSpectra,axis=-1)\n",
    "print(f\"Shape of tensor containing all ten elemental spectra {abundanceScaledElementalSpectra.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116c4210",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the element wise spectra\n",
    "linearMixedSpectra=tf.keras.backend.sum(abundanceScaledElementalSpectra,\n",
    "                                        axis=-1,\n",
    "                                        keepdims=False)\n",
    "print(f\"Shape of the linearly mixed spectra {linearMixedSpectra.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33771b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the model\n",
    "unmixingModel=tf.keras.Model(inputs=inputLayer,\n",
    "                             outputs=[regularAbundanceEmbedding,\n",
    "                                      nuclearAbundanceEmbedding,\n",
    "                                      linearMixedSpectra,\n",
    "                                      abundanceScaledElementalSpectra],\n",
    "                             name=\"Regularized_Constrained_Dual_Encoder_Unmxing_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934317fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create loss functions for the embeddings, Mean Squared Error\n",
    "regularAbundanceLossFunction=tf.keras.losses.MeanSquaredError(name=\"Reg_Abc_Loss\")\n",
    "nuclearAbundanceLossFunction=tf.keras.losses.MeanSquaredError(name=\"Nuc_Abc_Loss\")\n",
    "#create the loss function for the reconstructed spectra, Cosine loss\n",
    "recontructedSpectraLoss=tf.keras.losses.CosineSimilarity(name=\"Recon_Loss\")\n",
    "#create the optimizer\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "#set the number of epochs the model is to be trained for\n",
    "noOfEpochs=300\n",
    "#set the batch size\n",
    "batchSize=179\n",
    "\n",
    "#create the regularizer\n",
    "spectralDisimilarityRegularizer=spectralDisimilarityRegularization(name=\"Disim_Reg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c94698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "unmixingModel.compile(optimizer=optimizer,\n",
    "                      loss=[regularAbundanceLossFunction,\n",
    "                            nuclearAbundanceLossFunction,\n",
    "                            recontructedSpectraLoss,\n",
    "                            spectralDisimilarityRegularizer],\n",
    "                      loss_weights=[1e-2,\n",
    "                                    1,\n",
    "                                    1e-5,\n",
    "                                    1e-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4ec480",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the address where the untrained model will be saved\n",
    "#untrainedModelWeightsAddress=\"C:/ML4Sci/Ml4Sci_GRS_abundance_estimation/Models/untrained_Regularized_Constrainted_Dual_Unmixing_Model_With_PReLU_Weights.h5\"\n",
    "untrainedModelWeightsAddress=\"D:/Non-academic/GSOC23/untrained_Regularized_Constrainted_Dual_Unmixing_Model_With_PReLU_Weights_and_Linear_Decoder.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcf5514",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the untrained model\n",
    "unmixingModel.save_weights(untrainedModelWeightsAddress,\n",
    "                           overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498215d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if the GPU is available\n",
    "if len(tf.config.list_physical_devices('GPU'))==1:\n",
    "    print(\"GPU available\")\n",
    "else:\n",
    "    print(\"GPU unavailable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93df655",
   "metadata": {},
   "outputs": [],
   "source": [
    "noOfXticks=3\n",
    "noOfYticks=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8301f71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an array to save the element-wise learnt spectra across folds\n",
    "learntElementalSpectra=np.zeros((noOfChannels,\n",
    "                                 fullAbundanceEmbedding.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cad8ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "unmixingModel.load_weights(untrainedModelWeightsAddress)\n",
    "#compile the model\n",
    "unmixingModel.compile(optimizer=optimizer,\n",
    "                      loss=[regularAbundanceLossFunction,\n",
    "                            nuclearAbundanceLossFunction,\n",
    "                            recontructedSpectraLoss,\n",
    "                            spectralDisimilarityRegularizer],\n",
    "                      loss_weights=[1e-2,\n",
    "                                    1,\n",
    "                                    1e-5,\n",
    "                                    1e-1])\n",
    "\n",
    "#fit the model to the current fold's data\n",
    "currentModelTrainingHistory=unmixingModel.fit(x=preprocessedSpectra,\n",
    "                                                        y=[regularElementalAbundances,\n",
    "                                                           nuclearElementalAbundances,\n",
    "                                                           preprocessedSpectra,\n",
    "                                                           nuclearElementalAbundances],\n",
    "                                                        batch_size=batchSize,\n",
    "                                                        epochs=noOfEpochs)\n",
    "\n",
    "\n",
    "#save the training history of the current model\n",
    "modelTrainingHistories.append(currentModelTrainingHistory)\n",
    "\n",
    "\n",
    "\n",
    "#set the address where the untrained model will be saved\n",
    "trainedModelWeightsAddress=\"D:/Non-academic/GSOC23/trained_Regularized_Constrainted_Dual_Unmixing_Model_With_PReLU_Weights_and_Linear_Decoder.h5\"\n",
    "\n",
    "#save the untrained model\n",
    "unmixingModel.save_weights(trainedModelWeightsAddress,\n",
    "                           overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8faeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#iterate through all the elements\n",
    "for i in range(len(allElementNames)):\n",
    "\n",
    "    #get the mean spectrum for the current element\n",
    "    currentElementSpectrum=unmixingModel.get_layer(allElementNames[i]+\"_Spectra\").get_weights()[0][0]\n",
    "\n",
    "    #save the spectrum\n",
    "    learntElementalSpectra[:,i]=currentElementSpectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3596602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a figure \n",
    "figure,axes=plt.subplots(nrows=2,\n",
    "                         ncols=5,\n",
    "                         figsize=(5*5,5*2),\n",
    "                         dpi=100,\n",
    "                         sharex=True,\n",
    "                         sharey=True)\n",
    "\n",
    "\n",
    "#iterate through all the elements\n",
    "for i in range(len(allElementNames)):\n",
    "\n",
    "    #get the name of the current element\n",
    "    currentElementName=allElementNames[i]\n",
    "\n",
    "    #get the mean spectrum for the current element\n",
    "    currentElementSpectrum=learntElementalSpectra[:,i]\n",
    "\n",
    "    #plot the spectrum\n",
    "    axes[i//5,i%5].bar(relaventEnergyBands,\n",
    "                       currentElementSpectrum/np.linalg.norm(currentElementSpectrum),\n",
    "                       lw=10,\n",
    "                       width=10)\n",
    "\n",
    "    #add the title\n",
    "    axes[i//5,i%5].set_title(currentElementName,\n",
    "                             fontsize=baseFontSize*1.2)\n",
    "\n",
    "    #set the margin\n",
    "    axes[i//5,i%5].margins(0.01)\n",
    "\n",
    "    #add xticks and label\n",
    "    if i//5==1:\n",
    "        axes[i//5,i%5].set_xticks(np.arange(np.amin(relaventEnergyBands),\n",
    "                                            np.amax(relaventEnergyBands)+np.ptp(relaventEnergyBands)/noOfXticks,\n",
    "                                            np.ptp(relaventEnergyBands)/noOfXticks),\n",
    "                                  labels=np.round(np.arange(np.amin(relaventEnergyBands),\n",
    "                                                            np.amax(relaventEnergyBands)+np.ptp(relaventEnergyBands)/noOfXticks,\n",
    "                                                            np.ptp(relaventEnergyBands)/noOfXticks),\n",
    "                                                  0).astype('int'),\n",
    "                                  fontsize=baseFontSize*1.1)\n",
    "        axes[i//5,i%5].set_xlabel(\"KeV\",fontsize=baseFontSize*1.2)\n",
    "\n",
    "    #add yticks and label\n",
    "    if i%5==0:\n",
    "        axes[i//5,i%5].set_ylabel(\"log(Counts/min) ratioed\",fontsize=baseFontSize*1.2)\n",
    "\n",
    "    axes[i//5,i%5].set_yticks(np.arange(0,\n",
    "                                np.amax(currentElementSpectrum)+np.ptp(currentElementSpectrum)/noOfYticks,\n",
    "                                np.ptp(currentElementSpectrum)/noOfYticks),\n",
    "                      labels=np.round(np.arange(0,\n",
    "                                                np.amax(currentElementSpectrum)+np.ptp(currentElementSpectrum)/noOfYticks,\n",
    "                                                np.ptp(currentElementSpectrum)/noOfYticks),\n",
    "                                      2),\n",
    "                      fontsize=baseFontSize*1.1)\n",
    "#add a title\n",
    "figure.suptitle(f\"Element-wise Learnt spectra\",\n",
    "                fontsize=baseFontSize*1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49f0721",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import uniform_filter from scipy\n",
    "from scipy.ndimage import uniform_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06402ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an array to hold the smoothened element-wise spectra\n",
    "smoothenedElementWiseSpectra=np.zeros_like(learntElementalSpectra)\n",
    "\n",
    "#create a figure \n",
    "figure,axes=plt.subplots(nrows=2,\n",
    "                         ncols=5,\n",
    "                         figsize=(5*5,5*2),\n",
    "                         dpi=100,\n",
    "                         sharex=True,\n",
    "                         sharey=True)\n",
    "\n",
    "#iterate through the element-wise spectra and smoothen them\n",
    "for i in range(len(allElementNames)):\n",
    "    \n",
    "    #get the name of the current element\n",
    "    currentElementName=allElementNames[i]\n",
    "    \n",
    "    #get the mean spectrum for the current element\n",
    "    currentElementSpectrum=learntElementalSpectra[:,i]\n",
    "    \n",
    "    #normalize and smoothen the spectra\n",
    "    currentElementSpectrum=currentElementSpectrum/np.linalg.norm(currentElementSpectrum)\n",
    "    \n",
    "    #smoothen the spectrum\n",
    "    currentElementSpectrum=uniform_filter(currentElementSpectrum,\n",
    "                                          size=9)\n",
    "    currentElementSpectrum=currentElementSpectrum/np.linalg.norm(currentElementSpectrum)\n",
    "    \n",
    "    #plot the spectrum\n",
    "    axes[i//5,i%5].plot(relaventEnergyBands,\n",
    "                        currentElementSpectrum,\n",
    "                        lw=3)\n",
    "\n",
    "    #add the title\n",
    "    axes[i//5,i%5].set_title(currentElementName,\n",
    "                             fontsize=baseFontSize*1.2)\n",
    "\n",
    "    #set the margin\n",
    "    axes[i//5,i%5].margins(0.01)\n",
    "\n",
    "    #add xticks and label\n",
    "    if i//5==1:\n",
    "        axes[i//5,i%5].set_xticks(np.arange(np.amin(relaventEnergyBands),\n",
    "                                            np.amax(relaventEnergyBands)+np.ptp(relaventEnergyBands)/noOfXticks,\n",
    "                                            np.ptp(relaventEnergyBands)/noOfXticks),\n",
    "                                  labels=np.round(np.arange(np.amin(relaventEnergyBands),\n",
    "                                                            np.amax(relaventEnergyBands)+np.ptp(relaventEnergyBands)/noOfXticks,\n",
    "                                                            np.ptp(relaventEnergyBands)/noOfXticks),\n",
    "                                                  0).astype('int'),\n",
    "                                  fontsize=baseFontSize*1.1)\n",
    "        axes[i//5,i%5].set_xlabel(\"KeV\",fontsize=baseFontSize*1.2)\n",
    "\n",
    "    #add yticks and label\n",
    "    if i%5==0:\n",
    "        axes[i//5,i%5].set_ylabel(\"log(Counts/min) ratioed\",fontsize=baseFontSize*1.2)\n",
    "\n",
    "    axes[i//5,i%5].set_yticks(np.arange(0,\n",
    "                                np.amax(currentElementSpectrum)+np.ptp(currentElementSpectrum)/noOfYticks,\n",
    "                                np.ptp(currentElementSpectrum)/noOfYticks),\n",
    "                      labels=np.round(np.arange(0,\n",
    "                                                np.amax(currentElementSpectrum)+np.ptp(currentElementSpectrum)/noOfYticks,\n",
    "                                                np.ptp(currentElementSpectrum)/noOfYticks),\n",
    "                                      2),\n",
    "                      fontsize=baseFontSize*1.1)\n",
    "#add a title\n",
    "figure.suptitle(f\"Smoothened Element-wise Learnt spectra\",\n",
    "                fontsize=baseFontSize*1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99d98cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
